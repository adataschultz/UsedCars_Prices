{"cells":[{"cell_type":"markdown","source":["# Used Car Prices CarGurus on Azure: Create Datastore & Train Multilayer Perceptron"],"metadata":{"id":"Qxfr585nRyx4"}},{"cell_type":"markdown","source":["## Create an Azure Files Datastore\n","Connect to the Azure Machine Learning workspace with `MLClient`."],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"8sl7d2XxZ27E"}},{"cell_type":"code","source":["from azure.ai.ml import MLClient\n","from azure.identity import DefaultAzureCredential\n","\n","# Authenticate\n","credential = DefaultAzureCredential()\n","\n","# Get a handle to the workspace\n","ml_client = MLClient(\n","    credential=credential,\n","    subscription_id='a134465f-eb15-4297-b902-3c97d4c81838',\n","    resource_group_name='aschultzdata',\n","    workspace_name='ds-ml-env',\n",")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1691262495542},"id":"ZTxJIzmwZ27E"}},{"cell_type":"markdown","source":["Create the datastore specifying the name of the datastore, the description, the account, the name of the container, the protocol and the account key"],"metadata":{"id":"pZg34BcT_Q3h"}},{"cell_type":"code","source":["from azure.ai.ml.entities import AzureBlobDatastore\n","from azure.ai.ml.entities import AccountKeyConfiguration\n","\n","store = AzureBlobDatastore(\n","    name='usedcars_datastore',\n","    description='Datastore for Used Cars',\n","    account_name='dsmlenv8898281366',\n","    container_name='usedcarscargurus',\n","    protocol='https',\n","    credentials=AccountKeyConfiguration(\n","        account_key='XXXxxxXXXxXXXXxxXXXXXxXXXXXxXxxXxXXXxXXXxXXxxxXXxxXXXxXxXXXxxXxxXXXXxxxxxXXxxxxxxXXXxXXX'\n","    ),\n",")\n","\n","ml_client.create_or_update(store)"],"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"AzureBlobDatastore({'type': <DatastoreType.AZURE_BLOB: 'AzureBlob'>, 'name': 'usedcars_datastore', 'description': 'Datastore for Used Cars', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourceGroups/aschultzdata/providers/Microsoft.MachineLearningServices/workspaces/ds-ml-env/datastores/usedcars_datastore', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpu-standardds12v2/code/Users/aschultz.data/UsedCarsCarGurus/Models/DL/MLP', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f543aae2740>, 'credentials': {'type': 'account_key'}, 'container_name': 'usedcarscargurus', 'account_name': 'dsmlenv8898281366', 'endpoint': 'core.windows.net', 'protocol': 'https'})"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"gather":{"logged":1691262500431},"id":"00WxBQpbZ27G","outputId":"12bf3265-b735-407e-f4e0-6fec5dc75a7b"}},{"cell_type":"markdown","source":["Then upload the train/test sets to the `usedcarscargurus` container."],"metadata":{"nteract":{"transient":{"deleting":false}},"id":"7EygsnQRZ27H"}},{"cell_type":"markdown","source":["# Train a model\n","First, create a compute instance to run a notebook in Azure Machine Learning studio. Then connect to the workspace and create the compute resource (CPU or GPU), if it has not all ready been created.\n","\n","\n"],"metadata":{"id":"0p0OqxR0Z26w"}},{"cell_type":"markdown","source":["## Create a compute cluster to run the job"],"metadata":{"id":"VzRhu2sHAOMt"}},{"cell_type":"code","source":["from azure.ai.ml.entities import AmlCompute\n","\n","# Define the name of the compute cluster\n","gpu_compute_target = 'gpu-cluster-NC4as-T4-v3'\n","\n","try:\n","    # Examine if the cluster already exists\n","    gpu_cluster = ml_client.compute.get(gpu_compute_target)\n","    print(\n","        f\"You already have a cluster named {gpu_compute_target}, we'll reuse it as is.\"\n","    )\n","\n","except Exception:\n","    print('Creating a new gpu compute target...')\n","\n","    # Create the Azure Machine Learning compute object with specified components\n","    gpu_cluster = AmlCompute(\n","        name=gpu_compute_target,\n","        # On-demand VM service\n","        type='amlcompute',\n","        # VM Family\n","        size='Standard_NC4as_T4_v3',\n","        # Minimum nodes in the cluster\n","        min_instances=0,\n","        # Nodes in the cluster\n","        max_instances=1,\n","        # Time (seconds) the node will run after the job finishes/terminates\n","        idle_time_before_scale_down=180,\n","        # Type of tier: Dedicated or LowPriority\n","        tier='Dedicated',\n","    )\n","    print(\n","        f\"AMLCompute with name {gpu_cluster.name} will be created, with compute size {gpu_cluster.size}\"\n","    )\n","    # Pass the object to MLClient's create_or_update method\n","    gpu_cluster = ml_client.compute.begin_create_or_update(gpu_cluster)"],"outputs":[{"output_type":"stream","name":"stdout","text":"Creating a new gpu compute target...\nAMLCompute with name gpu-cluster-NC4as-T4-v3 will be created, with compute size Standard_NC4as_T4_v3\n"}],"execution_count":null,"metadata":{"gather":{"logged":1693867121907},"name":"cpu_compute_target","outputId":"1385047e-8948-4cc9-b56c-b14f5cfb0c52","id":"DWn2i_SkXrxK"}},{"cell_type":"markdown","source":["## Create the job environment\n","The environment lists the components of the runtime and the libraries installed on the compute for training the model."],"metadata":{"id":"K5oMdA7qZ263"}},{"cell_type":"code","source":["import os\n","\n","dependencies_dir = './dependencies'\n","os.makedirs(dependencies_dir, exist_ok=True)"],"outputs":[],"execution_count":null,"metadata":{"gather":{"logged":1691253967791},"name":"dependencies_dir","id":"cZDKjNUxZ264"}},{"cell_type":"markdown","source":["Now we can write the `conda` file into the `dependencies` directory."],"metadata":{"id":"L8TMRaMMZ265"}},{"cell_type":"code","source":["%%writefile {dependencies_dir}/conda.yaml\n","name: model-env\n","channels:\n","  - conda-forge\n","dependencies:\n","  - python=3.8.5\n","  - pip=23.1.2\n","  - numpy=1.21.6\n","  - scikit-learn==1.1.2\n","  - scipy\n","  - pandas>=1.1,<1.2\n","  - pip:\n","    - inference-schema[numpy-support]==1.3.0\n","    - mlflow\n","    - azureml-mlflow==1.50.0\n","    - psutil==5.9.0\n","    - tqdm\n","    - ipykernel\n","    - matplotlib\n","    - tensorflow==2.12\n","    - keras-tuner==1.1.3"],"outputs":[{"output_type":"stream","name":"stdout","text":"Writing ./dependencies/conda.yaml\n"}],"execution_count":null,"metadata":{"name":"write_model","id":"ekkNaqT3Z265","outputId":"e4588433-a5a8-4e26-f071-9c87f2ad3111"}},{"cell_type":"markdown","source":["The created `conda.yaml` file allows for the environment to be created and registered in the workspace."],"metadata":{"id":"K1DU3gmfZ266"}},{"cell_type":"code","source":["from azure.ai.ml.entities import Environment\n","\n","custom_env_name = 'aml-usedcars-gpu-mlp'\n","\n","custom_job_env = Environment(\n","    name=custom_env_name,\n","    description='Custom environment for Used Cars MLP job',\n","    tags={'tensorflow': '2.12'},\n","    conda_file=os.path.join(dependencies_dir, 'conda.yaml'),\n","    image='mcr.microsoft.com/azureml/curated/tensorflow-2.12-cuda11:6',\n",")\n","custom_job_env = ml_client.environments.create_or_update(custom_job_env)\n","\n","print(\n","    f'Environment with name {custom_job_env.name} is registered to workspace, the environment version is {custom_job_env.version}'\n",")"],"outputs":[{"output_type":"stream","name":"stdout","text":"Environment with name aml-usedcars-gpu-mlp is registered to workspace, the environment version is 5\n"}],"execution_count":null,"metadata":{"gather":{"logged":1691264298701},"name":"custom_env_name","id":"cyW7ppH3Z266","outputId":"2005a994-ac1e-4659-9ace-19a4d805634f"}},{"cell_type":"markdown","source":["## Create training script\n","First, the source folder where the training script, `main.py`, will be stored needs to be created."],"metadata":{"id":"WeKknDz_Z268"}},{"cell_type":"code","source":["train_src_dir = './src'\n","os.makedirs(train_src_dir, exist_ok=True)"],"outputs":[],"execution_count":null,"metadata":{"gather":{"logged":1691275102931},"name":"train_src_dir","id":"rcd7kg_bZ268"}},{"cell_type":"markdown","source":["The training script includes preparing the environment, reading the data, data preparation, model training, saving the model and evaluating the model. This includes specifying the dependencies to import and utilize, setting the seed, defining the input/output arguments of `argparse`, reading the train/test sets, preprocessing the data for dummy variables and scaling using the `StandardScaler`. Then the number of samples and features are logged with `MLFlow`. It uses this to then train a `MLP` model using the best parameters from `keras-tuner` where the `Loss` and `Val_Loss` are logged with `MLFlow` with defined callbacks. The model is then saved and evaluated for the model loss, the metrics of the train/test sets and the predicted vs. actual minimum/average/maximum price, which are logged as `MLFlow` artifacts and metrics.\n","\n"],"metadata":{"id":"9LeNUVw6xF4p"}},{"cell_type":"code","source":["%%writefile {train_src_dir}/main.py\n","import os\n","import random\n","import numpy as np\n","import warnings\n","import argparse\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","import mlflow\n","import tensorflow as tf\n","import datetime\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from keras.callbacks import Callback\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import matplotlib.pyplot as plt\n","warnings.filterwarnings('ignore')\n","\n","# Set seed for reproducibility\n","def init_seeds(seed=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","    session_conf = tf.compat.v1.ConfigProto()\n","    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n","                                            inter_op_parallelism_threads=1)\n","    os.environ['TF_CUDNN_DETERMINISTIC'] = 'True'\n","    os.environ['TF_DETERMINISTIC_OPS'] = 'True'\n","    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(),\n","                                config=session_conf)\n","    tf.compat.v1.keras.backend.set_session(sess)\n","\n","    return sess\n","\n","init_seeds(seed=42)\n","\n","def main():\n","    \"\"\"Main function of the script.\"\"\"\n","\n","    # Input and output arguments\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--train_data', type=str, help='path to input train data')\n","    parser.add_argument('--test_data', type=str, help='path to input test data')\n","    parser.add_argument('--epochs', required=False, default=30, type=int)\n","    parser.add_argument('--batch_size', required=False, default=1, type=int)\n","    args = parser.parse_args()\n","\n","    # Start Logging\n","    mlflow.start_run()\n","\n","    ###################\n","    #<prepare the data>\n","    ###################\n","    print(' '.join(f'{k}={v}' for k, v in vars(args).items()))\n","\n","    print('input train data:', args.train_data)\n","    print('input test data:', args.test_data)\n","\n","    trainDF = pd.read_csv(args.train_data, low_memory=False)\n","    testDF = pd.read_csv(args.test_data, low_memory=False)\n","\n","    train_label = trainDF[['price']]\n","    test_label = testDF[['price']]\n","\n","    train_features = trainDF.drop(columns = ['price'])\n","    test_features = testDF.drop(columns = ['price'])\n","\n","    train_features = pd.get_dummies(train_features, drop_first=True)\n","    test_features = pd.get_dummies(test_features, drop_first=True)\n","\n","    sc = StandardScaler()\n","    train_features = pd.DataFrame(sc.fit_transform(train_features))\n","    test_features = pd.DataFrame(sc.transform(test_features))\n","\n","    mlflow.log_metric('num_samples', train_features.shape[0])\n","    mlflow.log_metric('num_features', train_features.shape[1])\n","\n","    print(f'Training with data of shape {train_features.shape}')\n","\n","    ####################\n","    #</prepare the data>\n","    ####################\n","\n","    ##################\n","    #<train the model>\n","    ##################\n","    model = Sequential()\n","    model.add(Dense(130, input_dim=53, kernel_initializer='normal',\n","                    activation='relu'))\n","    model.add(Dense(130, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(130, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(70, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(130, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(70, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(130, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(70, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(130, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(70, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(130, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(130, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(130, kernel_initializer='normal', activation='relu'))\n","    model.add(Dropout(0.3))\n","    model.add(Dense(1))\n","\n","    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n","    model.compile(loss='mae', metrics=['mse'], optimizer=opt)\n","    model.summary()\n","\n","    # Log metrics\n","    class LogRunMetrics(Callback):\n","        # Callback at the end of every epoch\n","        def on_epoch_end(self, epoch, log):\n","            # log a value repeated which creates a list\n","            mlflow.log_metric('Loss', log['loss'])\n","            mlflow.log_metric('Val_Loss', log['val_loss'])\n","\n","    log_folder = 'logs/fit/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n","\n","    filepath = 'MLP_weights_only_HPO1_bestModel.tf'\n","    checkpoint_dir = os.path.dirname(filepath)\n","\n","    callbacks_list = [EarlyStopping(monitor='val_loss', patience=5),\n","                      ModelCheckpoint(filepath, monitor='mse',\n","                                      save_best_only=True, mode='min'),\n","                      LogRunMetrics()]\n","\n","    history = model.fit(train_features, train_label, epochs=args.epochs,\n","                        batch_size=args.batch_size, validation_split=0.2,\n","                        callbacks=callbacks_list)\n","\n","    model.save('./MLP_HPO1_bestModel', save_format='tf')\n","\n","    # Load model for more training or later use\n","    #filepath = 'MLP_weights_only_b4_HPO1_bestModel.h5'\n","    #model = tf.keras.models.load_model('./MLP_HPO1_bestModel_tf.h5')\n","    #model.load_weights(filepath)\n","\n","    ##################\n","    #</train the model>\n","    ##################\n","\n","    #####################\n","    #<evaluate the model>\n","    #####################\n","    plt.title('Model Error for Price')\n","    plt.plot(history.history['loss'], label='train')\n","    plt.plot(history.history['val_loss'], label='val_loss')\n","    plt.ylabel('Error [Price]')\n","    plt.xlabel('Epoch')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.savefig('Loss vs. Price.png')\n","    mlflow.log_artifact('Loss vs. Price.png')\n","    plt.close()\n","\n","    losses = pd.DataFrame(model.history.history)\n","    losses.plot()\n","    plt.title('Model Error for Price')\n","    plt.ylabel('Error [Price]')\n","    plt.xlabel('Epoch')\n","    plt.legend(loc='upper right')\n","    plt.grid(True)\n","    plt.savefig('Error vs. Price.png')\n","    mlflow.log_artifact('Error vs. Price.png')\n","    plt.close()\n","\n","    pred_train = model.predict(train_features)\n","\n","    # Metrics: Train set\n","    train_mae = mean_absolute_error(train_label[:], pred_train[:])\n","    train_mse = mean_squared_error(train_label[:], pred_train[:])\n","    train_rmse = np.sqrt(mean_squared_error(train_label[:], pred_train[:]))\n","    train_r2 = r2_score(train_label[:], pred_train[:])\n","\n","    pred_test = model.predict(test_features)\n","\n","    # Metrics: Test set\n","    test_mae = mean_absolute_error(test_label[:], pred_test[:])\n","    test_mse = mean_squared_error(test_label[:], pred_test[:])\n","    test_rmse = np.sqrt(mean_squared_error(test_label[:], pred_test[:]))\n","    test_r2 = r2_score(test_label[:], pred_test[:])\n","\n","    mlflow.log_metric('train_mae', train_mae)\n","    mlflow.log_metric('train_mse', train_mse)\n","    mlflow.log_metric('train_rmse', train_rmse)\n","    mlflow.log_metric('train_r2', train_r2)\n","    mlflow.log_metric('test_mae', test_mae)\n","    mlflow.log_metric('test_mse', test_mse)\n","    mlflow.log_metric('test_rmse', test_rmse)\n","    mlflow.log_metric('test_r2', test_r2)\n","\n","    MaximumPrice = np.amax(test_label)\n","    PredictedMaxPrice = np.amax(pred_test)\n","    AveragePrice = np.average(test_label)\n","    PredictedAveragePrice = np.average(pred_test)\n","    MinimumPrice = np.amin(test_label)\n","    PredictedMinimumPrice = np.amin(pred_test)\n","\n","    mlflow.log_metric('Maximum Price', MaximumPrice)\n","    mlflow.log_metric('Predicted Maximum Price', PredictedMaxPrice)\n","    mlflow.log_metric('Average Price', AveragePrice)\n","    mlflow.log_metric('Predicted Average Price', PredictedAveragePrice)\n","    mlflow.log_metric('Minimum Price', MinimumPrice)\n","    mlflow.log_metric('Predicted Minimum Price', PredictedMinimumPrice)\n","\n","    ###################\n","    #</evaluate the model>\n","    ###################\n","\n","    # Stop Logging\n","    mlflow.end_run()\n","\n","if __name__ == \"__main__\":\n","    main()"],"outputs":[{"output_type":"stream","name":"stdout","text":"Writing ./src/main.py\n"}],"execution_count":null,"metadata":{"name":"write_main","id":"tVUi7gOTZ26-","outputId":"cc596171-990e-4143-a7fa-d22a0db1225a"}},{"cell_type":"markdown","source":[" ## Train the model with specified components\n","To train the model, a `command job` configured with the input specifying the  input data, the number of epochs and the batch size, which then runs the `training script` using the specified compute resource, environment, and the parameters specified to be logged needs to be submitted as a job."],"metadata":{"id":"ZOaZt0agZ27A"}},{"cell_type":"code","source":["from azure.ai.ml import command\n","from azure.ai.ml import Input\n","\n","registered_model_name = 'usedcars_mlp_model'\n","\n","job = command(\n","    inputs=dict(\n","        train_data=Input(\n","            type='uri_file',\n","            path='azureml://datastores/usedcars_datastore/paths/usedCars_trainSet.csv',\n","        ),\n","        test_data=Input(\n","            type='uri_file',\n","            path = 'azureml://datastores/usedcars_datastore/paths/usedCars_testSet.csv',\n","        ),\n","        epochs=50,\n","        batch_size=4,\n","        registered_model_name=registered_model_name,\n","    ),\n","\n","    code='./src/',\n","    command='python main.py --train_data ${{inputs.train_data}} --test_data ${{inputs.test_data}} --epochs ${{inputs.epochs}} --batch_size ${{inputs.batch_size}}',\n","    environment='aml-usedcars-gpu-mlp@latest',\n","    compute='gpu-cluster-NC4as-T4-v3',\n","    display_name='usedcars_mlp_prediction',\n",")"],"outputs":[],"execution_count":null,"metadata":{"gather":{"logged":1691275120026},"name":"registered_model_name","id":"Zo38JVx9Z27B"}},{"cell_type":"markdown","source":["## Submit the job\n","\n","Then this job can be submitted to run in `Azure Machine Learning Studio` using the `create_or_update` command with `ml_client`."],"metadata":{"id":"sqjXP3ICZ27B"}},{"cell_type":"code","source":["ml_client.create_or_update(job)"],"outputs":[{"output_type":"stream","name":"stderr","text":"Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n\u001b[32mUploading src (0.01 MBs): 100%|██████████| 9073/9073 [00:00<00:00, 963415.70it/s]\n\u001b[39m\n\n"},{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"Command({'parameters': {}, 'init': False, 'name': 'plucky_frame_0ncbbdml4f', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': '1849dbcf-77c8-4922-a5b9-ef31b90ac904'}, 'print_as_yaml': True, 'id': '/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourceGroups/aschultzdata/providers/Microsoft.MachineLearningServices/workspaces/ds-ml-env/jobs/plucky_frame_0ncbbdml4f', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpu-standardds12v2/code/Users/aschultz.data/UsedCarsCarGurus/Models/DL/MLP', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f56857fbd00>, 'serialize': <msrest.serialization.Serializer object at 0x7f5685601210>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'usedcars_mlp_prediction', 'experiment_name': 'MLP', 'compute': 'gpu-cluster-NC4as-T4-v3', 'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourceGroups/aschultzdata/providers/Microsoft.MachineLearningServices/workspaces/ds-ml-env?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/plucky_frame_0ncbbdml4f?wsid=/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourcegroups/aschultzdata/workspaces/ds-ml-env&tid=82f58b44-0a84-4add-9752-ad76c1fdebb1', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'train_data': {'type': 'uri_file', 'path': 'azureml://datastores/usedcars_datastore/paths/usedCars_trainSet.csv', 'mode': 'ro_mount'}, 'test_data': {'type': 'uri_file', 'path': 'azureml://datastores/usedcars_datastore/paths/usedCars_testSet.csv', 'mode': 'ro_mount'}, 'epochs': '50', 'batch_size': '4', 'registered_model_name': 'usedcars_mlp_model'}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.plucky_frame_0ncbbdml4f', 'mode': 'rw_mount'}}, 'inputs': {'train_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f5685603160>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f56856023b0>, 'epochs': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f56856018d0>, 'batch_size': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f56856026b0>, 'registered_model_name': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7f5685601330>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7f56856017b0>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'plucky_frame_0ncbbdml4f', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f56857fbd00>, 'serialize': <msrest.serialization.Serializer object at 0x7f5685601660>, 'command': 'python main.py --train_data ${{inputs.train_data}} --test_data ${{inputs.test_data}} --epochs ${{inputs.epochs}} --batch_size ${{inputs.batch_size}}', 'code': '/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourceGroups/aschultzdata/providers/Microsoft.MachineLearningServices/workspaces/ds-ml-env/codes/8358d999-9417-4d30-9223-e2f2c5d60553/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourceGroups/aschultzdata/providers/Microsoft.MachineLearningServices/workspaces/ds-ml-env/environments/aml-usedcars-gpu-mlp/versions/5', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'usedcars_mlp_prediction', 'is_deterministic': True, 'inputs': {'train_data': {'type': 'uri_file', 'path': 'azureml://datastores/usedcars_datastore/paths/usedCars_trainSet.csv', 'mode': 'ro_mount'}, 'test_data': {'type': 'uri_file', 'path': 'azureml://datastores/usedcars_datastore/paths/usedCars_testSet.csv', 'mode': 'ro_mount'}, 'epochs': {'type': 'string', 'default': '50'}, 'batch_size': {'type': 'string', 'default': '4'}, 'registered_model_name': {'type': 'string', 'default': 'usedcars_mlp_model'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.plucky_frame_0ncbbdml4f', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': [], 'CommandComponent__additional_includes_obj': None}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourceGroups/aschultzdata/providers/Microsoft.MachineLearningServices/workspaces/ds-ml-env?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/plucky_frame_0ncbbdml4f?wsid=/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourcegroups/aschultzdata/workspaces/ds-ml-env&tid=82f58b44-0a84-4add-9752-ad76c1fdebb1', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f56857fbd00>}, 'instance_id': 'c8eb92ec-b19b-4a08-8eb8-eb1dc7c5f6c0', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'aml-usedcars-gpu-mlp:5', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})","text/html":"<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>MLP</td><td>plucky_frame_0ncbbdml4f</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/plucky_frame_0ncbbdml4f?wsid=/subscriptions/a134465f-eb15-4297-b902-3c97d4c81838/resourcegroups/aschultzdata/workspaces/ds-ml-env&amp;tid=82f58b44-0a84-4add-9752-ad76c1fdebb1\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"},"metadata":{}}],"execution_count":null,"metadata":{"gather":{"logged":1691275127957},"name":"create_job","id":"wBnsa0vRZ27C","outputId":"5cc55a0d-a490-4a37-ecb6-0cb078752ae0"}},{"cell_type":"markdown","source":["## View Job Output\n","The submitted job can then be viewed by selecting the link in the output of the previous cell. The logged information with `MLFlow` including the model metrics and saved graphs can then be viewed/downloaded when the job completes."],"metadata":{"id":"GiJgIuLxZ27D"}}],"metadata":{"categories":["SDK v2","tutorials"],"kernel_info":{"name":"python310-sdkv2"},"kernelspec":{"name":"python310-sdkv2","language":"python","display_name":"Python 3.10 - SDK v2"},"language_info":{"name":"python","version":"3.10.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"microsoft":{"host":{"AzureML":{"notebookHasBeenCompleted":true}},"ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":0}